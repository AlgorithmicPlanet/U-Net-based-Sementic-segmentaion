{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRNM2Qs4vZqn"
      },
      "source": [
        "**** Algo Name : Sementic segmentation Skeleton ....... **\n",
        "..\n",
        "\n",
        "Algo techStack : Deep Learning (CNN)\n",
        "\n",
        "Algo Architecture used : U-Net ++ (UNet++ differs from the original U-Net in three ways: 1) having convolution layers on skip pathways, which bridges the semantic gap between encoder and decoder feature maps. 2) having dense skip connections on skip pathways, which improves gradient flow.)\n",
        "\n",
        "GPU Used : yes\n",
        "\n",
        "processing type : Single Model processing\n",
        "\n",
        "Model extention : Keras format\n",
        "\n",
        "framework used : Tenserflow 2.3\n",
        "\n",
        "Algo Creater : Shoeb Ahmad (shoeb.ahmad@bridgei2i.com , er.shoaib10@gmail.\n",
        "com ..)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxeskBwcsoL-"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip 'data_train.zip' -d path"
      ],
      "metadata": {
        "id": "npeqsSjvq0og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use(\"ggplot\")\n",
        "%matplotlib inline\n",
        "import gc\n",
        "\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, Dropout, concatenate, UpSampling2D\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "  \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "import shutil\n",
        "import random \n",
        "\n"
      ],
      "metadata": {
        "id": "QgKwTl3Y3ZLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Seeding \n",
        "seed = 2019\n",
        "border = 5\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "tf.seed = seed"
      ],
      "metadata": {
        "id": "aFIw-bSk6thB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global parameters**"
      ],
      "metadata": {
        "id": "mr43IaKIBtP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = r'/content/drive/My Drive/Colab Notebooks/U-Net Semantic Segmentation/' #(Add your data path accordingly)\n",
        "\n",
        "w, h = 304,304  #(Standerd Images Size for Unet ++ training , prefer not to change until it not required)\n",
        "\n",
        "dropout_rate = 0.5 #(0.5 is an standerd but can be changed based on developer preference)\n",
        "\n",
        "min_lr = 0.00001\n",
        "\n",
        "batch_size = 6 \n",
        "\n",
        "epochs = 10"
      ],
      "metadata": {
        "id": "buZAT8w_B36s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Colab Notebooks/U-Net Semantic Segmentation/'"
      ],
      "metadata": {
        "id": "mZmoti3LQI2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ttwk4GIMP-Cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for count in os.listdir(path+'data_train'):\n",
        "#     if count.split('_')[-1].split('.')[0] == 'preview':\n",
        "#       #os.remove(path+'data_train'+'//'+count)\n",
        "#       print(count) #chechink the deleted file\n",
        "#     if count.split('_')[-1].split('.')[0] == 'msk':\n",
        "#         shutil.move(path+'data_train'+'//'+count,path+'data_train'+'//'+'mask'+'//'+count)\n"
      ],
      "metadata": {
        "id": "Anbdh3pBq5qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZOxbTxNi8G9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = []\n",
        "train_mask = []\n",
        "for i in os.listdir(path+'data_train'+'//'+'mask'):\n",
        "  train_mask.append(i)\n",
        "for i2 in os.listdir(path+'data_train'+'//'+'images'):\n",
        "  train.append(i2)  "
      ],
      "metadata": {
        "id": "HMaS5YMW5doH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train) , len(train_mask))"
      ],
      "metadata": {
        "id": "YYOSrxzJ5o40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(train), h, w, 3), dtype=np.float32)\n",
        "y = np.zeros((len(train_mask), h, w, 1), dtype=np.float32)"
      ],
      "metadata": {
        "id": "3U9xWTCg-nPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n, (img, mimg) in tqdm(enumerate(zip(train, train_mask))):\n",
        "  # print(n, img, mimg)\n",
        "  # Load images\n",
        "  img = load_img(path+'data_train'+'//'+'images'+'//'+img)\n",
        "  x_img = img_to_array(img)\n",
        "  x_img = resize(x_img, (h, w, 3), mode = 'constant', preserve_range = True)\n",
        "  # # Load masks\n",
        "  mask = img_to_array(load_img(path+'data_train'+'//'+'mask'+'//'+mimg, color_mode = \"grayscale\"))\n",
        "  mask = resize(mask, (h, w, 1), mode = 'constant', preserve_range = True)\n",
        "  # # Save images\n",
        "  X[n] = x_img/255.0\n",
        "  y[n] = mask/255.0"
      ],
      "metadata": {
        "id": "XsoSvqL1_w91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Save the files in Numpy array for reusability\n",
        "# np.save('/content/drive/My Drive/Colab Notebooks/U-Net Semantic Segmentation/data_train/X.npy', X)\n",
        "# np.save('/content/drive/My Drive/Colab Notebooks/U-Net Semantic Segmentation/data_train/y.npy', y)\n",
        "# print(X.shape, y.shape)\n",
        "X = np.load('/content/drive/My Drive/Colab Notebooks/U-Net Semantic Segmentation/data_train/X.npy')\n",
        "y = np.load('/content/drive/My Drive/Colab Notebooks/U-Net Semantic Segmentation/data_train/y.npy')\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "nfKpdKIs_1fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train and valid\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "jm_Y70UeA_H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize any randome image along with the mask\n",
        "ix = random.randint(0, len(X_train))\n",
        "has_mask = y_train[ix].max() > 0 # salt indicator\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 15))\n",
        "\n",
        "ax1.imshow(X_train[ix, ..., 0], interpolation = 'bilinear')\n",
        "if has_mask: # if salt\n",
        "    # draw a boundary(contour) in the original image separating salt and non-salt areas\n",
        "    ax1.contour(y_train[ix].squeeze(), colors = 'k', linewidths = 5, levels = [0.5])\n",
        "ax1.set_title('lungs infection Image')\n",
        "ax1.set_axis_off()\n",
        "ax2.imshow(y_train[ix].squeeze(), cmap = 'gray', interpolation = 'bilinear')\n",
        "ax2.set_title('Mask lungs infection Image')\n",
        "ax2.set_axis_off()"
      ],
      "metadata": {
        "id": "-gErvRR8Bm0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def conv_batchnorm_relu_block(input_tensor, nb_filter, kernel_size=3):\n",
        "\n",
        "    x = Conv2D(nb_filter, (kernel_size, kernel_size), padding='same')(input_tensor)\n",
        "    x = BatchNormalization(axis=2)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def UnetPP(input_shape, n_labels, using_deep_supervision=False):\n",
        "\n",
        "    nb_filter = [32,64,128,256,512]\n",
        "\n",
        "    # Set image data format to channels first\n",
        "    global bn_axis\n",
        "\n",
        "    K.set_image_data_format(\"channels_last\")\n",
        "    bn_axis = -1\n",
        "    inputs = Input(shape=input_shape, name='input_image')\n",
        "\n",
        "    conv1_1 = conv_batchnorm_relu_block(inputs, nb_filter=nb_filter[0])\n",
        "    pool1 = AvgPool2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n",
        "\n",
        "    conv2_1 = conv_batchnorm_relu_block(pool1, nb_filter=nb_filter[1])\n",
        "    pool2 = AvgPool2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n",
        "\n",
        "    up1_2 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up12', padding='same')(conv2_1)\n",
        "    conv1_2 = concatenate([up1_2, conv1_1], name='merge12', axis=bn_axis)\n",
        "    conv1_2 = conv_batchnorm_relu_block(conv1_2,  nb_filter=nb_filter[0])\n",
        "\n",
        "    conv3_1 = conv_batchnorm_relu_block(pool2, nb_filter=nb_filter[2])\n",
        "    pool3 = AvgPool2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
        "\n",
        "    up2_2 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up22', padding='same')(conv3_1)\n",
        "    conv2_2 = concatenate([up2_2, conv2_1], name='merge22', axis=bn_axis)\n",
        "    conv2_2 = conv_batchnorm_relu_block(conv2_2, nb_filter=nb_filter[1])\n",
        "\n",
        "    up1_3 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up13', padding='same')(conv2_2)\n",
        "    conv1_3 = concatenate([up1_3, conv1_1, conv1_2], name='merge13', axis=bn_axis)\n",
        "    conv1_3 = conv_batchnorm_relu_block(conv1_3, nb_filter=nb_filter[0])\n",
        "\n",
        "    conv4_1 = conv_batchnorm_relu_block(pool3, nb_filter=nb_filter[3])\n",
        "    pool4 = AvgPool2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
        "\n",
        "    up3_2 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up32', padding='same')(conv4_1)\n",
        "    conv3_2 = concatenate([up3_2, conv3_1], name='merge32', axis=bn_axis)\n",
        "    conv3_2 = conv_batchnorm_relu_block(conv3_2, nb_filter=nb_filter[2])\n",
        "\n",
        "    up2_3 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up23', padding='same')(conv3_2)\n",
        "    conv2_3 = concatenate([up2_3, conv2_1, conv2_2], name='merge23', axis=bn_axis)\n",
        "    conv2_3 = conv_batchnorm_relu_block(conv2_3, nb_filter=nb_filter[1])\n",
        "\n",
        "    up1_4 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up14', padding='same')(conv2_3)\n",
        "    conv1_4 = concatenate([up1_4, conv1_1, conv1_2, conv1_3], name='merge14', axis=bn_axis)\n",
        "    conv1_4 = conv_batchnorm_relu_block(conv1_4, nb_filter=nb_filter[0])\n",
        "\n",
        "    conv5_1 = conv_batchnorm_relu_block(pool4, nb_filter=nb_filter[4])\n",
        "\n",
        "    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
        "    conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n",
        "    conv4_2 = conv_batchnorm_relu_block(conv4_2, nb_filter=nb_filter[3])\n",
        "\n",
        "    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
        "    conv3_3 = concatenate([up3_3, conv3_1, conv3_2], name='merge33', axis=bn_axis)\n",
        "    conv3_3 = conv_batchnorm_relu_block(conv3_3, nb_filter=nb_filter[2])\n",
        "\n",
        "    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
        "    conv2_4 = concatenate([up2_4, conv2_1, conv2_2, conv2_3], name='merge24', axis=bn_axis)\n",
        "    conv2_4 = conv_batchnorm_relu_block(conv2_4, nb_filter=nb_filter[1])\n",
        "\n",
        "    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
        "    conv1_5 = concatenate([up1_5, conv1_1, conv1_2, conv1_3, conv1_4], name='merge15', axis=bn_axis)\n",
        "    conv1_5 = conv_batchnorm_relu_block(conv1_5, nb_filter=nb_filter[0])\n",
        "\n",
        "    nestnet_output_1 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_1',padding='same')(conv1_2)\n",
        "    nestnet_output_2 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_2', padding='same' )(conv1_3)\n",
        "    nestnet_output_3 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_3', padding='same')(conv1_4)\n",
        "    nestnet_output_4 = Conv2D(n_labels, (1, 1), activation='sigmoid', name='output_4', padding='same')(conv1_5)\n",
        "\n",
        "    if using_deep_supervision:\n",
        "        model = Model(input=inputs, output=[nestnet_output_1,\n",
        "                                            nestnet_output_2,\n",
        "                                            nestnet_output_3,\n",
        "                                            nestnet_output_4])\n",
        "    else:\n",
        "        model = Model(inputs=inputs, outputs=nestnet_output_4)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "zAE3zxyABrBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "K.clear_session()\n",
        "\n",
        "# input_img = Input((h, w, 3), name='img')\n",
        "# del model\n",
        "model = UnetPP(input_shape = (304, 304,3), n_labels=1)\n",
        "metrics = [\"accuracy\", \n",
        "           tf.keras.metrics.AUC(), \n",
        "           tf.keras.metrics.SensitivityAtSpecificity(0.5), \n",
        "           tf.keras.metrics.SpecificityAtSensitivity(0.5)]\n",
        "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=metrics)\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "6LvQGcJ1B2-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "GmUFSC7tB5ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=10, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr = 0.00001, verbose=1),\n",
        "    ModelCheckpoint(path+'model-UnetPP.h5', verbose=2 ,monitor = 'val_loss', save_best_only=True),\n",
        "    CSVLogger(\"dataUnetPP.csv\"),\n",
        "    TensorBoard(log_dir='./logs')\n",
        "]"
      ],
      "metadata": {
        "id": "QOKULNYoB-PA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(X_train, y_train, batch_size , epochs , callbacks=callbacks, validation_data=(X_test, y_test), use_multiprocessing=True)"
      ],
      "metadata": {
        "id": "7Xyzv7NHCKO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result = pd.DataFrame(results.history)\n",
        "df_result.sort_values('val_loss', ascending=True, inplace = True)\n",
        "df_result"
      ],
      "metadata": {
        "id": "XmeuPT31CVXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15,6))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
        "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"log_loss\")\n",
        "plt.legend();\n",
        "\n",
        "plt.figure(figsize = (15,6))\n",
        "plt.title(\"Learning curve\")\n",
        "plt.plot(results.history[\"accuracy\"], label=\"Accuracy\")\n",
        "plt.plot(results.history[\"val_accuracy\"], label=\"val_Accuracy\")\n",
        "plt.plot(np.argmax(results.history[\"val_accuracy\"]), np.max(results.history[\"val_accuracy\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "rBeFdHXAQ-Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('model-UnetPP.h5')"
      ],
      "metadata": {
        "id": "y539ZX4ARKwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=1)"
      ],
      "metadata": {
        "id": "Xmu-0DHhRYkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on train, val and test\n",
        "preds_train = model.predict(X_train, verbose=1)\n",
        "preds_val = model.predict(X_test, verbose=1)"
      ],
      "metadata": {
        "id": "g7tjIXvXRfK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
      ],
      "metadata": {
        "id": "1MmGCSQJccTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
        "    \"\"\"Function to plot the results\"\"\"\n",
        "    if ix is None:\n",
        "        ix = random.randint(0, len(X))\n",
        "\n",
        "    has_mask = y[ix].max() > 0\n",
        "\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
        "    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n",
        "    if has_mask:\n",
        "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[0].set_title('Lungs Image')\n",
        "    ax[0].set_axis_off()\n",
        "\n",
        "    ax[1].imshow(y[ix].squeeze())\n",
        "    ax[1].set_title('Lungs Mask Image')\n",
        "    ax[1].set_axis_off()\n",
        "\n",
        "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[2].set_title('lungs Image Predicted')\n",
        "    ax[2].set_axis_off()\n",
        "    \n",
        "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
        "    if has_mask:\n",
        "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
        "    ax[3].set_title('lungs Mask Image Predicted binary');\n",
        "    ax[3].set_axis_off()    "
      ],
      "metadata": {
        "id": "uaH42DBjcDj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if training data looks all right\n",
        "plot_sample(X_train, y_train, preds_train, preds_train_t, ix=14)"
      ],
      "metadata": {
        "id": "DZ_lOXUscMAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(X_train, y_train, preds_train, preds_train_t)"
      ],
      "metadata": {
        "id": "WGHL71rOcQcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(X_train, y_train, preds_train, preds_train_t)"
      ],
      "metadata": {
        "id": "br-TJwCpcwbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(X_train, y_train, preds_train, preds_train_t)"
      ],
      "metadata": {
        "id": "T8cAkPQPc555"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hNnCuPkN0YiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JaY3hKdF1MDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "URxf7UMz2DC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4_MQ5EUy2XzI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Colabs_Train.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}